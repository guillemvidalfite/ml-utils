{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import ssl\n",
    "import urllib3\n",
    "import json\n",
    "\n",
    "from elasticsearch import Elasticsearch, JSONSerializer\n",
    "from elasticsearch.connection import create_ssl_context\n",
    "from elasticsearch.helpers import parallel_bulk\n",
    "from elasticsearch.helpers import scan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "urllib3.disable_warnings() # This is insecure\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic search connection procedures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elastic_client(server=\"local\", write=False):\n",
    "    if server == \"local\":\n",
    "        if write:\n",
    "            serializer = NpJSONSerializer()\n",
    "        else:\n",
    "            serializer = JSONSerializer()\n",
    "        return Elasticsearch(host=\"localhost\",\n",
    "                             port=9200,\n",
    "                             serializer=serializer)\n",
    "    elif server in {\"dev\", \"horizon\", \"prod\"}:\n",
    "        # All the other servers are remote hosts with similar configs\n",
    "        if server == \"prod\":\n",
    "            host = \"daimler-elastic.vpc.bigml.com\"\n",
    "        elif server == \"horizon\":\n",
    "            host = \"daimler-elastic.horizon.bigml.com\"\n",
    "        else:\n",
    "            host = \"daimler-elastic.dev.bigml.com\"\n",
    "\n",
    "        if write:\n",
    "            serializer = NpJSONSerializer()\n",
    "        else:\n",
    "            serializer = JSONSerializer()\n",
    "        # Set up ssl context to disable cert verification\n",
    "        ssl_context = create_ssl_context()\n",
    "        ssl_context.check_hostname = False\n",
    "        ssl_context.verify_mode = ssl.CERT_NONE\n",
    "        return Elasticsearch(host=host,\n",
    "                             port=443,\n",
    "                             http_auth=(\"dev\", \"paroafCa\"),\n",
    "                             serializer=serializer,\n",
    "                             ssl_context=ssl_context,\n",
    "                             use_ssl=True,\n",
    "                             request_timeout=50,\n",
    "                             timeout=50,\n",
    "                             max_retries=5, \n",
    "                             retry_on_timeout=True)\n",
    "    else:\n",
    "        logger.warning(\"unknown server '%s'\", server)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciate Elastic Search connection to dev:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Elasticsearch([{}])>\n"
     ]
    }
   ],
   "source": [
    "ES = get_elastic_client(\"dev\")\n",
    "print(ES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Get Repaired Welds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE QUERY\n",
    "with open('elastic_query_all_repairs.json', \"r\") as f:\n",
    "      query_repair_welds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUEST_TIMEOUT = 100.  # Timeout for the elastic queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current batch 10000\n",
      "Current batch 20000\n",
      "Loop finished, building dataframe \n",
      "22979\n"
     ]
    }
   ],
   "source": [
    "repaired_welds_df = pd.DataFrame()\n",
    "\n",
    "num_batch = 1\n",
    "welds = []\n",
    "\n",
    "for current_weld in scan(ES, index=\"ml_toolbox_raw_data\", \n",
    "                                  query=query_repair_welds, \n",
    "                                  scroll='15m',\n",
    "                                  raise_on_error=True,\n",
    "                                  size=5000,\n",
    "                                  request_timeout=REQUEST_TIMEOUT):\n",
    "\n",
    "    if num_batch % 10000 == 0:\n",
    "      print(\"Current batch %s\" % num_batch)\n",
    "    \n",
    "    num_batch = num_batch + 1\n",
    "\n",
    "    # gather current bucket key information\n",
    "    welds.append(current_weld[\"_source\"])\n",
    "\n",
    "\n",
    "## build dataframe from welds list\n",
    "print(\"Loop finished, building dataframe \")\n",
    "print(len(welds))\n",
    "\n",
    "repaired_welds_df = pd.DataFrame.from_records(welds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Get successful welds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE QUERY\n",
    "with open('elastic_query_random_welds.json', \"r\") as f:\n",
    "      query_random_welds = json.load(f)\n",
    "\n",
    "with open('elastic_query_random_welds2.json', \"r\") as f:\n",
    "      query_random_welds2 = json.load(f)\n",
    "        \n",
    "with open('elastic_query_random_welds3.json', \"r\") as f:\n",
    "      query_random_welds3 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current batch 10000\n",
      "Current batch 20000\n",
      "Current batch 30000\n",
      "Loop finished, building dataframe \n",
      "32783\n"
     ]
    }
   ],
   "source": [
    "num_batch = 1\n",
    "welds = []\n",
    "\n",
    "for current_weld in scan(ES, index=\"ml_toolbox_raw_data\", \n",
    "                                  query=query_random_welds, \n",
    "                                  scroll='15m',\n",
    "                                  raise_on_error=True,\n",
    "                                  size=5000,\n",
    "                                  request_timeout=REQUEST_TIMEOUT):\n",
    "\n",
    "    if num_batch % 10000 == 0:\n",
    "      print(\"Current batch %s\" % num_batch)\n",
    "    \n",
    "    num_batch = num_batch + 1\n",
    "\n",
    "    # gather current bucket key information\n",
    "    welds.append(current_weld[\"_source\"])\n",
    "\n",
    "print(\"Loop finished, building dataframe \")\n",
    "print(len(welds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "## append welds list to dataframe\n",
    "repaired_welds_df = repaired_welds_df.append(pd.DataFrame.from_records(welds), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current batch 10000\n",
      "Current batch 20000\n",
      "Current batch 30000\n",
      "Loop finished, building dataframe \n",
      "32805\n"
     ]
    }
   ],
   "source": [
    "num_batch = 1\n",
    "welds = []\n",
    "\n",
    "for current_weld in scan(ES, index=\"ml_toolbox_raw_data\", \n",
    "                                  query=query_random_welds2, \n",
    "                                  scroll='15m',\n",
    "                                  raise_on_error=True,\n",
    "                                  size=5000,\n",
    "                                  request_timeout=REQUEST_TIMEOUT):\n",
    "\n",
    "    if num_batch % 10000 == 0:\n",
    "      print(\"Current batch %s\" % num_batch)\n",
    "    \n",
    "    num_batch = num_batch + 1\n",
    "\n",
    "    # gather current bucket key information\n",
    "    welds.append(current_weld[\"_source\"])\n",
    "\n",
    "print(\"Loop finished, building dataframe \")\n",
    "print(len(welds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## append welds list to dataframe\n",
    "repaired_welds_df = repaired_welds_df.append(pd.DataFrame.from_records(welds), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current batch 10000\n",
      "Current batch 20000\n",
      "Current batch 30000\n",
      "Loop finished, building dataframe \n",
      "33827\n"
     ]
    }
   ],
   "source": [
    "num_batch = 1\n",
    "welds = []\n",
    "\n",
    "for current_weld in scan(ES, index=\"ml_toolbox_raw_data\", \n",
    "                                  query=query_random_welds3, \n",
    "                                  scroll='15m',\n",
    "                                  raise_on_error=True,\n",
    "                                  size=5000,\n",
    "                                  request_timeout=REQUEST_TIMEOUT):\n",
    "\n",
    "    if num_batch % 10000 == 0:\n",
    "      print(\"Current batch %s\" % num_batch)\n",
    "    \n",
    "    num_batch = num_batch + 1\n",
    "\n",
    "    # gather current bucket key information\n",
    "    welds.append(current_weld[\"_source\"])\n",
    "\n",
    "print(\"Loop finished, building dataframe \")\n",
    "print(len(welds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## append welds list to dataframe\n",
    "repaired_welds_df = repaired_welds_df.append(pd.DataFrame.from_records(welds), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122394, 199)\n"
     ]
    }
   ],
   "source": [
    "print(repaired_welds_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "repaired_welds_df.to_csv('/Users/guillem/Data/Customers/Daimler/insights/repairs_insights_dataset.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
